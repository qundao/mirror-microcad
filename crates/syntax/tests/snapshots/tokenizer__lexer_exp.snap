---
source: crates/syntax/tests/tokenizer.rs
expression: "lex(input).collect::<Vec<_>>()"
---
[
    SpannedToken {
        span: 0..5,
        token: LiteralFloat(
            ".1e-3",
        ),
    },
    SpannedToken {
        span: 5..6,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 6..11,
        token: LiteralFloat(
            ".1e+3",
        ),
    },
    SpannedToken {
        span: 11..12,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 12..16,
        token: LiteralFloat(
            ".1e3",
        ),
    },
    SpannedToken {
        span: 16..17,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 17..21,
        token: LiteralFloat(
            "1.e3",
        ),
    },
    SpannedToken {
        span: 21..22,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 22..27,
        token: LiteralFloat(
            "1.2e3",
        ),
    },
    SpannedToken {
        span: 27..28,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 28..31,
        token: LiteralFloat(
            "1e3",
        ),
    },
]
