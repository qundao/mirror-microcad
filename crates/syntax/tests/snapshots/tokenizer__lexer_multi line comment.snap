---
source: crates/syntax/tests/tokenizer.rs
expression: lex(input)
---
Ok(
    [
        SpannedToken {
            span: 0..1,
            token: Normal(
                Identifier(
                    "a",
                ),
            ),
        },
        SpannedToken {
            span: 2..3,
            token: Normal(
                OperatorAssignment,
            ),
        },
        SpannedToken {
            span: 4..5,
            token: Normal(
                LiteralInt(
                    "1",
                ),
            ),
        },
        SpannedToken {
            span: 5..6,
            token: Normal(
                SigilSemiColon,
            ),
        },
        SpannedToken {
            span: 7..44,
            token: Normal(
                MultiLineComment(
                    "/** multi\n    line\n    comment\n    */",
                ),
            ),
        },
        SpannedToken {
            span: 49..50,
            token: Normal(
                Identifier(
                    "b",
                ),
            ),
        },
        SpannedToken {
            span: 51..52,
            token: Normal(
                OperatorAssignment,
            ),
        },
        SpannedToken {
            span: 53..54,
            token: Normal(
                LiteralInt(
                    "2",
                ),
            ),
        },
        SpannedToken {
            span: 54..55,
            token: Normal(
                SigilSemiColon,
            ),
        },
    ],
)
