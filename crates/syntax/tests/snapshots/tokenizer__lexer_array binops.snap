---
source: crates/syntax/tests/tokenizer.rs
expression: lex(input)
---
[
    SpannedToken {
        span: 0..1,
        token: SigilOpenSquareBracket,
    },
    SpannedToken {
        span: 1..2,
        token: LiteralInt(
            "1",
        ),
    },
    SpannedToken {
        span: 2..3,
        token: SigilComma,
    },
    SpannedToken {
        span: 3..4,
        token: LiteralInt(
            "2",
        ),
    },
    SpannedToken {
        span: 4..5,
        token: SigilCloseSquareBracket,
    },
    SpannedToken {
        span: 5..6,
        token: SigilQuote,
    },
    SpannedToken {
        span: 7..9,
        token: OperatorEqual,
    },
    SpannedToken {
        span: 10..11,
        token: SigilOpenSquareBracket,
    },
    SpannedToken {
        span: 11..12,
        token: LiteralInt(
            "1",
        ),
    },
    SpannedToken {
        span: 12..13,
        token: SigilComma,
    },
    SpannedToken {
        span: 13..14,
        token: LiteralInt(
            "2",
        ),
    },
    SpannedToken {
        span: 14..15,
        token: SigilCloseSquareBracket,
    },
    SpannedToken {
        span: 15..17,
        token: Identifier(
            "cm",
        ),
    },
]
