---
source: crates/syntax/tests/tokenizer.rs
expression: "lex(input).collect::<Vec<_>>()"
---
[
    SpannedToken {
        span: 0..16,
        token: InnerDocComment(
            "//! Doc comment1",
        ),
    },
    SpannedToken {
        span: 16..21,
        token: Whitespace(
            "\n    ",
        ),
    },
    SpannedToken {
        span: 21..37,
        token: InnerDocComment(
            "//! Doc comment2",
        ),
    },
    SpannedToken {
        span: 37..42,
        token: Whitespace(
            "\n    ",
        ),
    },
]
