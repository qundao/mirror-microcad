---
source: crates/syntax/tests/tokenizer.rs
expression: "lex(input).collect::<Vec<_>>()"
---
[
    SpannedToken {
        span: 0..2,
        token: KeywordFn,
    },
    SpannedToken {
        span: 2..3,
        token: SigilOpenBracket,
    },
    SpannedToken {
        span: 3..4,
        token: Identifier(
            "a",
        ),
    },
    SpannedToken {
        span: 4..5,
        token: SigilColon,
    },
    SpannedToken {
        span: 5..6,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 6..12,
        token: Identifier(
            "Length",
        ),
    },
    SpannedToken {
        span: 12..13,
        token: SigilCloseBracket,
    },
    SpannedToken {
        span: 13..14,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 14..16,
        token: SigilSingleArrow,
    },
    SpannedToken {
        span: 16..17,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 17..23,
        token: Identifier(
            "Length",
        ),
    },
    SpannedToken {
        span: 23..24,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 24..25,
        token: SigilOpenCurlyBracket,
    },
    SpannedToken {
        span: 25..26,
        token: Identifier(
            "a",
        ),
    },
    SpannedToken {
        span: 26..27,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 27..28,
        token: OperatorMultiply,
    },
    SpannedToken {
        span: 28..29,
        token: Whitespace(
            " ",
        ),
    },
    SpannedToken {
        span: 29..30,
        token: LiteralInt(
            "2",
        ),
    },
    SpannedToken {
        span: 30..31,
        token: SigilCloseCurlyBracket,
    },
]
