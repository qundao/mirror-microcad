---
source: crates/syntax/tests/tokenizer.rs
expression: lex(input)
---
Ok(
    [
        SpannedToken {
            span: 35..36,
            token: LiteralString(
                [
                    SpannedToken {
                        span: 1..8,
                        token: Content(
                            "string ",
                        ),
                    },
                    SpannedToken {
                        span: 23..24,
                        token: FormatStart(
                            (
                                [
                                    SpannedToken {
                                        span: 9..13,
                                        token: Identifier(
                                            "more",
                                        ),
                                    },
                                    SpannedToken {
                                        span: 14..15,
                                        token: OperatorAdd,
                                    },
                                    SpannedToken {
                                        span: 16..23,
                                        token: Identifier(
                                            "complex",
                                        ),
                                    },
                                ],
                                [],
                            ),
                        ),
                    },
                    SpannedToken {
                        span: 24..35,
                        token: Content(
                            " expression",
                        ),
                    },
                ],
            ),
        },
    ],
)
