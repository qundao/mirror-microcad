---
source: crates/syntax/tests/tokenizer.rs
expression: lex(input)
---
Ok(
    [
        SpannedToken {
            span: 25..26,
            token: Normal(
                String(
                    [
                        SpannedToken {
                            span: 1..8,
                            token: String(
                                Content(
                                    "string ",
                                ),
                            ),
                        },
                        SpannedToken {
                            span: 13..14,
                            token: String(
                                FormatStart(
                                    [
                                        SpannedToken {
                                            span: 9..13,
                                            token: Normal(
                                                Identifier(
                                                    "with",
                                                ),
                                            ),
                                        },
                                    ],
                                ),
                            ),
                        },
                        SpannedToken {
                            span: 14..25,
                            token: String(
                                Content(
                                    " expression",
                                ),
                            ),
                        },
                    ],
                ),
            ),
        },
    ],
)
