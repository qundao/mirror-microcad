---
source: crates/syntax/tests/tokenizer.rs
expression: lex(input)
---
[
    SpannedToken {
        span: 25..26,
        token: FormatStringStart,
    },
    SpannedToken {
        span: 1..8,
        token: StringContent(
            "string ",
        ),
    },
    SpannedToken {
        span: 13..14,
        token: StringFormatOpen,
    },
    SpannedToken {
        span: 9..13,
        token: Identifier(
            "with",
        ),
    },
    SpannedToken {
        span: 13..14,
        token: StringFormatClose,
    },
    SpannedToken {
        span: 14..25,
        token: StringContent(
            " expression",
        ),
    },
    SpannedToken {
        span: 25..26,
        token: FormatStringEnd,
    },
]
